{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engines - Assignment 3\n",
    "\n",
    "## 3.3 - Evaluation using non-binary judgments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(filename):\n",
    "    average_scores = []\n",
    "    # Open text file\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split line by tab\n",
    "            line = line.strip().split(' ')\n",
    "            # Get the query number and relevance score\n",
    "            query = line[0]\n",
    "            score = int(line[1])\n",
    "            # Append to list\n",
    "            average_scores.append((query, score))\n",
    "    return average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@50 on averaged: 0.6625572798294809\n"
     ]
    }
   ],
   "source": [
    "def compute_dcg(scores):\n",
    "    # Initialize DCG\n",
    "    dcg = 0\n",
    "    # Iterate over scores\n",
    "    for i, (document, score) in enumerate(scores):\n",
    "        # Compute DCG\n",
    "        dcg += score / np.log2(i + 2)\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def compute_ndcg(scores):\n",
    "    # Compute DCG\n",
    "    dcg = compute_dcg(scores)\n",
    "    # Sort scores by relevance\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    # Compute ideal DCG\n",
    "    idcg = compute_dcg(scores)\n",
    "    # Return NDCG\n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "print('NDCG@50 on averaged: ' +\n",
    "      str(compute_ndcg(compute_scores('average_relevance_filtered.txt')[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@50 with relevance feedback: 0.5436781945442729\n"
     ]
    }
   ],
   "source": [
    "print('NDCG@50 with relevance feedback: ' +\n",
    "      str(compute_ndcg(compute_scores('new_relevance.txt')[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@50 with relevance feedback and Mathematic.f removed: 0.5145346367129126\n"
     ]
    }
   ],
   "source": [
    "scores = compute_scores('new_relevance.txt')\n",
    "for i, (name, score) in enumerate(scores):\n",
    "    if (name == 'Mathematics.f'):\n",
    "        scores[i] = (name, 0)\n",
    "        break\n",
    "print('NDCG@50 with relevance feedback and Mathematic.f removed: ' +\n",
    "      str(compute_ndcg(scores[:50])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
